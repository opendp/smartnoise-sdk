name: OpenDP Spark Unit Tests

on: [pull_request, workflow_dispatch]

jobs:
  build-linux:
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: [3.8]
      max-parallel: 5
    steps:
    - uses: actions/checkout@v2
    - name: Set up miniconda
      uses: conda-incubator/setup-miniconda@v2
      with:
        miniconda-version: "latest"
        auto-update-conda: true
        auto-activate-base: true
        python-version: ${{ matrix.python-version }}
    - name: Upgrade pip
      shell: bash -l {0}
      run: |
        conda install pip
        conda update pip
    # - name: Install cython and pandas
    #   shell: bash -l {0}
    #   run: |
    #     pip install --no-cache-dir cython
    #     pip install --no-cache-dir numpy
    #     pip install --no-cache-dir pandas
    # - name: Get development headers
    #   shell: bash -l {0}
    #   run: |
    #     sudo apt-get update
    #     sudo apt-get -yq upgrade
    #     sudo apt-get -yq -o Debug::pkgProblemResolver=true -o Debug::Acquire::http=true install python3-dev libpq-dev unixodbc-dev cargo openssl libssl-dev openjdk-11-jre-headless
    - name: Get development headers
      shell: bash -l {0}
      run: |
        sudo apt-get update
        sudo apt-get -yq upgrade
        sudo apt-get -yq install openjdk-11-jre-headless
    - name: Install dependencies
      shell: bash -l {0}
      run: |
        pip install --no-cache-dir numpy
        pip install --no-cache-dir -r tests/requirements.txt
        pip install --no-cache-dir pyspark
    - name: Install opendp-smartnoise
      shell: bash -l {0}
      run: |
        pip install ./sdk
        export TEST_SPARK=1
        export SKIP_PANDAS=1
        pip show pyspark
        python tests/setup/download.py
    - name: Test SDK
      shell: bash -l {0}
      run: |
        export TEST_SPARK=1
        export SKIP_PANDAS=1
        pytest tests/sdk -s -m "not torch"  --junitxml=./TEST-TEST.xml
