{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Private Synopsis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data\n",
    "\n",
    "First we load the California demographic data into a Spark `DataFrame`.  We let Spark infer the column names and types, then clean things up a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+---+---+----+-------+------+-----+-----+-------+\n",
      "|PersonID|state| puma|sex|age|educ| income|latino|black|asian|married|\n",
      "+--------+-----+-----+---+---+----+-------+------+-----+-----+-------+\n",
      "|       1|    6|60100|  0| 83|   9|20500.0| false|false|false|   true|\n",
      "|       2|    6|60100|  1| 81|   9| 4800.0| false|false|false|   true|\n",
      "|       3|    6|60100|  0| 45|   9|12000.0| false|false|false|   true|\n",
      "|       4|    6|60100|  1| 42|  12| 7200.0| false|false|false|   true|\n",
      "|       5|    6|60100|  0| 35|  11|55600.0| false|false|false|   true|\n",
      "+--------+-----+-----+---+---+----+-------+------+-----+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n",
      "There are 1223992 individuals in the data\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import FloatType, BooleanType\n",
    "\n",
    "filepath = \"../datasets/PUMS_large.csv\"\n",
    "pums = spark.read.load(filepath, format=\"csv\", sep=\",\",inferSchema=\"true\", header=\"true\")\n",
    "\n",
    "pums = pums.withColumnRenamed(\"_c0\", \"PersonID\")\n",
    "\n",
    "pums = pums.withColumn(\"income\", col(\"income\").cast(FloatType()))\n",
    "pums = pums.withColumn(\"latino\", col(\"latino\").cast(BooleanType()))\n",
    "pums = pums.withColumn(\"black\", col(\"black\").cast(BooleanType()))\n",
    "pums = pums.withColumn(\"asian\", col(\"asian\").cast(BooleanType()))\n",
    "pums = pums.withColumn(\"married\", col(\"married\").cast(BooleanType()))\n",
    "\n",
    "pums.show(5)\n",
    "print(\"There are {0} individuals in the data\".format(pums.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 167:==================================================>    (11 + 1) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|    ???|\n",
      "+-------+\n",
      "|1223992|\n",
      "+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from snsql import *\n",
    "\n",
    "pums.createOrReplaceTempView(\"PUMS_large\")\n",
    "\n",
    "\n",
    "metadata = '../datasets/PUMS_large.yaml'\n",
    "\n",
    "private_reader = from_connection(\n",
    "    spark, \n",
    "    metadata=metadata, \n",
    "    privacy=Privacy(epsilon=3.0, delta=1/1_000_000)\n",
    ")\n",
    "private_reader.reader.compare.search_path = [\"PUMS\"]\n",
    "\n",
    "\n",
    "res = private_reader.execute('SELECT COUNT(*) FROM PUMS_large')\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row in the data represents a unique individual.\n",
    "\n",
    "# Get Exact Values for Comparison\n",
    "\n",
    "The `private_reader` wraps an existing SparkSQL session and applies differential privacy.  We can access the underlying reader to get exact results with no differential privacy.  This is useful for comparing utility.  For example, we can compute the average income for individuals in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|  count|       avg(income)|\n",
      "+-------+------------------+\n",
      "|1223992|31070.466115791605|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = 'SELECT COUNT(*) AS count, AVG(income) FROM PUMS_large'\n",
    "\n",
    "reader = private_reader.reader # the underlying connection to Spark SQL\n",
    "\n",
    "res = reader.execute(query)\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Exact Synopsis\n",
    "\n",
    "We can use the `SparkReader` to create a synopsis file that calculates some metrics grouped by the dimensions in the data.  We can then load the synopsis into an Excel spreadsheet to use in a Pivot Table, or query the synopsis from Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+-------+------+-----+-----+----+------------------+\n",
      "|sex|age|educ|married|latino|black|asian|   n|            income|\n",
      "+---+---+----+-------+------+-----+-----+----+------------------+\n",
      "|  0| 18|   7|  false| false|false|false|1892|2764.0517970401693|\n",
      "|  1| 20|  11|  false| false|false|false|1855| 7020.706199460917|\n",
      "|  0| 19|   9|  false| false|false|false|1838| 7706.380848748639|\n",
      "|  0| 20|  11|  false| false|false|false|1722| 7904.883855981417|\n",
      "|  1| 21|  11|  false| false|false|false|1590| 9081.222641509434|\n",
      "|  0| 19|   9|  false|  true|false|false|1585| 7702.480757097792|\n",
      "|  0| 21|  11|  false| false|false|false|1519|  9836.19749835418|\n",
      "|  0| 20|   9|  false| false|false|false|1517|11827.940672379696|\n",
      "|  0| 20|   9|  false|  true|false|false|1409|10880.109297374023|\n",
      "|  1| 18|   7|  false| false|false|false|1408|2676.2613636363635|\n",
      "|  1| 19|   9|  false|  true|false|false|1401| 5252.779443254818|\n",
      "|  0| 18|   7|  false|  true|false|false|1367| 2766.517922457937|\n",
      "|  1| 19|  11|  false| false|false|false|1361| 5541.756061719324|\n",
      "|  1| 19|   9|  false| false|false|false|1300| 6302.875384615385|\n",
      "|  0| 22|  11|  false| false|false|false|1230|11989.367479674796|\n",
      "+---+---+----+-------+------+-----+-----+----+------------------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 180:====>                                                  (1 + 11) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20879 distinct dimensions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "query = 'SELECT sex, age, educ, married, latino, black, asian, COUNT(*) AS n, AVG(income) AS income FROM PUMS_large GROUP BY sex, age, educ, married, latino, black, asian ORDER BY n DESC'\n",
    "\n",
    "synopsis = private_reader.reader.execute(query)\n",
    "synopsis.show(15)\n",
    "print(\"{0} distinct dimensions\".format(synopsis.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have far fewer rows, but we can still recover the exact values.  For example, the average income queried from our synopsis exactly matches the average income we queried above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 186:===================================================> (193 + 7) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|  count|        avg_income|\n",
      "+-------+------------------+\n",
      "|1223992|31070.466115791605|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "synopsis.createOrReplaceTempView(\"Synopsis\")\n",
    "\n",
    "res = reader.execute(\"SELECT SUM(n) AS count, SUM(income * n) / SUM(n) AS avg_income FROM Synopsis\")\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have gone from 1.2 million rows to approximately 20,000 rows, so each row in our synopsis no longer represents an individual.  However, we have still not attempted to use any differential privacy, so our synopsis is not private.  For example, there are several dimensions in our synopsis which uniquely identify individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 189:=======================>                                (5 + 7) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+-------+------+-----+-----+---+-------+\n",
      "|sex|age|educ|married|latino|black|asian|  n| income|\n",
      "+---+---+----+-------+------+-----+-----+---+-------+\n",
      "|  1| 46|   9|   true| false| true| true|  1|28200.0|\n",
      "|  0| 65|   4|  false| false|false| true|  1| 9100.0|\n",
      "|  1| 44|   7|   true|  true|false| true|  1|20000.0|\n",
      "|  0| 88|  14|   true|  true|false|false|  1|48100.0|\n",
      "|  1| 31|   4|   true| false| true|false|  1| 7000.0|\n",
      "+---+---+----+-------+------+-----+-----+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "reader.execute(\"SELECT * FROM Synopsis WHERE n <= 1\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, cells with exact counts > 1 can still leak privacy.  To protect against these and other attacks, let's make our synopsis private.\n",
    "\n",
    "# Generate Private Synopsis\n",
    "\n",
    "To generate a private synopsis, we use the same query we used to create the exact synopsis, but we use a `PrivateReader`, which transparently adds differential privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+-------+------+-----+-----+----+--------+\n",
      "|sex|age|educ|married|latino|black|asian|   n|  income|\n",
      "+---+---+----+-------+------+-----+-----+----+--------+\n",
      "|  0| 18|   7|  false| false|false|false|1892| 2904.57|\n",
      "|  1| 20|  11|  false| false|false|false|1855| 7111.50|\n",
      "|  0| 19|   9|  false| false|false|false|1837| 7936.92|\n",
      "|  0| 20|  11|  false| false|false|false|1722| 7838.15|\n",
      "|  1| 21|  11|  false| false|false|false|1590| 8833.01|\n",
      "|  0| 19|   9|  false|  true|false|false|1584| 7714.33|\n",
      "|  0| 21|  11|  false| false|false|false|1519| 9757.01|\n",
      "|  0| 20|   9|  false| false|false|false|1517|11999.68|\n",
      "|  0| 20|   9|  false|  true|false|false|1409|10828.88|\n",
      "|  1| 18|   7|  false| false|false|false|1408| 2762.46|\n",
      "|  1| 19|   9|  false|  true|false|false|1401| 5268.12|\n",
      "|  0| 18|   7|  false|  true|false|false|1367| 2846.85|\n",
      "|  1| 19|  11|  false| false|false|false|1361| 5556.09|\n",
      "|  1| 19|   9|  false| false|false|false|1300| 6224.62|\n",
      "|  0| 22|  11|  false| false|false|false|1230|12024.97|\n",
      "+---+---+----+-------+------+-----+-----+----+--------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 213:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20879 distinct dimensions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DecimalType\n",
    "\n",
    "private_synopsis = private_reader.execute(query) # using same query from before\n",
    "private_synopsis = private_synopsis.withColumn('income', private_synopsis.income.cast(DecimalType(18, 2)))\n",
    "private_synopsis.show(15)\n",
    "print(\"{0} distinct dimensions\".format(private_synopsis.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the `PrivateReader` transparently adds noise, you will notice that the numbers change each time you run the cell above, sometimes even returning negative counts or negative incomes.  However, the larger aggregates are still fairly accurate, because the noise is symmetrical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 217:============================================>       (171 + 16) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|  count|  avg_income|\n",
      "+-------+------------+\n",
      "|1223971|31017.306549|\n",
      "+-------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 218:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "private_synopsis.persist().createOrReplaceTempView(\"PrivateSynopsis\")\n",
    "\n",
    "reader.execute(\"SELECT SUM(n) AS count, SUM(income * n) / SUM(n) AS avg_income FROM PrivateSynopsis\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we call `persist()` when loading the private synopsis into a view.  This is how we ensure that Spark doesn't generate a new synopsis every time we query the synopsis.  The goal of a synopsis is to support many queries from a single generation, and we do not want to pay additional `epsilon` privacy cost every time we use the synopsis.  If we create the synopsis once, we can export to Excel or persist in a view, then query indefinitely without incurring further privacy cost.\n",
    "\n",
    "## PrivateReader Parameters\n",
    "\n",
    "When we created the `PrivateReader` above, we passed in the `epsilon` parameter and wrapped our existing `SparkReader` we created earlier.  The `PrivateReader` simply intercepts calls to `SparkReader` and adds noise calibrated to the requested `epsilon`.  We also passed in some metadata describing the sensitivity of the fields in the data source, loaded from a YAML file.  In particular, the algorithm needed to know that the `income` field ranges between 0 and 500,000, in order to appropriately calibrate the noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PUMS.PUMS_large [0 rows]\n",
      "\t*PersonID [int] (unbounded)\n",
      "\tstate [int] (unbounded)\n",
      "\tpuma (card: 0)\n",
      "\tsex (card: 0)\n",
      "\tage [int] (0,100)\n",
      "\teduc (card: 0)\n",
      "\tincome [float] (0.0,500000.0)\n",
      "\tlatino (boolean)\n",
      "\tblack (boolean)\n",
      "\tasian (boolean)\n",
      "\tmarried (boolean)\n"
     ]
    }
   ],
   "source": [
    "import snsql\n",
    "meta = snsql.metadata.Metadata.from_file('../datasets/PUMS_large.yaml')\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also notice that the YAML file refers to the PUMS_large table with the prefix PUMS, which is a convention used in the SQL-92 specification allowing tables and views to be grouped together.  Although we are only querying a single source table here, the readers support querying over multiple tables.  Since our query does not specify the full disambiguated table name, we tell our reader to treat PUMS as a default namespace by specifying `private.reader.compare.search_path`.\n",
    "\n",
    "You can read more about the other `PrivateReader` options [here](https://opendifferentialprivacy.github.io/smartnoise-samples/docs/api/system/sql/private_reader.html#opendp.smartnoise.sql.private_reader.PrivateReaderOptions)\n",
    "\n",
    "# Censoring Infrequent Dimensions\n",
    "\n",
    "One option worth exploring further is the `censor_dims` option we set to `False` above.  Recall that the number of distinct dimensions in our private synopsis was exactly the same as the number of distinct dimesions in our exact synopsis.  In our exact synopsis, the existence of dimensions with exactly one member constituted a privacy leak.  Since we have added noise, dimensions with fewer than 2 members are significantly less useful:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+----+-------+------+-----+-----+---+----------+\n",
      "|sex|age|educ|married|latino|black|asian|  n|    income|\n",
      "+---+---+----+-------+------+-----+-----+---+----------+\n",
      "|  1| 74|  11|  false|  true| true|false|  1|-224928.36|\n",
      "|  0| 58|   2|  false|  true| true|false|  1|  44239.65|\n",
      "|  1| 19|  13|  false| false| true| true|  1|-166109.36|\n",
      "|  0| 19|   3|   true|  true|false| true|  1| 170144.94|\n",
      "|  1| 56|  12|  false|  true|false| true|  1|   8405.05|\n",
      "|  1| 84|  16|  false|  true|false|false|  1| 377023.71|\n",
      "|  1| 45|   9|   true| false| true| true|  1|  58083.91|\n",
      "|  0| 93|   7|  false| false|false| true|  1|-121255.44|\n",
      "+---+---+----+-------+------+-----+-----+---+----------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reader.execute(\"SELECT * FROM PrivateSynopsis WHERE n <= 1\").show(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is possible that the mere existence of a unique dimension combination in the data set would constitute a privacy failure.  For example, if this data represented people with a sensitive medical condition, mere membership would sensitive.  If we want to protect the queries further, we can tell the system to hide infrequent dimensions, adhering to epsilon, delta differential privacy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT sex, age, educ, married, latino, black, asian, COUNT(*) AS n, AVG(income) AS income FROM PUMS_large GROUP BY sex, age, educ, married, latino, black, asian ORDER BY n DESC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 256:=================================================>  (190 + 10) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13382 distinct dimensions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 257:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(query)\n",
    "delta = 1/1_200_000\n",
    "\n",
    "meta[\"PUMS.PUMS_large\"].censor_dims = True\n",
    "\n",
    "private_reader = from_connection(\n",
    "    spark, \n",
    "    metadata=meta,\n",
    "    privacy=Privacy(epsilon=3.0, delta=delta)\n",
    ")\n",
    "private_reader.reader\n",
    "private_reader.reader.compare.search_path = [\"PUMS\"]\n",
    "\n",
    "\n",
    "private_synopsis = private_reader.execute(query)\n",
    "print(\"{0} distinct dimensions\".format(private_synopsis.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 261:==============================================>     (179 + 16) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+\n",
      "|  count|      avg_income|\n",
      "+-------+----------------+\n",
      "|1207427|31181.1383100664|\n",
      "+-------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 262:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "private_synopsis.persist().createOrReplaceTempView(\"PrivateSynopsis\")\n",
    "\n",
    "reader.execute(\"SELECT SUM(n) AS count, SUM(income * n) / SUM(n) AS avg_income FROM PrivateSynopsis\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the outputs, you can see the private synopsis still computes an accurate average income, but we are missing about 6,500 dimensions, representing about 12,000 individuals.  It may be desirable to leave the synopsis like this, to indicate that some individuals have been dropped for privacy reasons.  In some settings, however, this is undesirable, because aggregate counts will be biased downward.  To resolve this, we can add an `other` dimension that recaptures the dropped dimension.\n",
    "\n",
    "## Recovering Infrequent Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combining 7497 distinct dimensions that were dropped.\n",
      "Selecting 16571 records from the dimensions that were censored\n"
     ]
    }
   ],
   "source": [
    "# get the dimensions\n",
    "other = 'SELECT DISTINCT sex, age, educ, married, latino, black, asian FROM PUMS_large EXCEPT (SELECT DISTINCT sex, age, educ, married, latino, black, asian FROM PrivateSynopsis)'\n",
    "other_dims = reader.execute(other)\n",
    "other_dims.persist().createOrReplaceTempView(\"OtherDims\")\n",
    "print(\"Combining {0} distinct dimensions that were dropped.\".format(other_dims.count()))\n",
    "\n",
    "# get rows that match censored dimensions\n",
    "filtered = 'SELECT t1.* FROM PUMS_large t1 LEFT SEMI JOIN OtherDims t2 ON ( t1.sex = t2.sex AND t1.age = t2.age AND t1.educ = t2.educ AND t1.married = t2.married AND t1.latino = t2.latino AND t1.black = t2.black AND t1.asian = t2.asian)'\n",
    "filtered_pums = reader.execute(filtered)\n",
    "filtered_pums.persist().createOrReplaceTempView(\"PUMS_censored\")\n",
    "print(\"Selecting {0} records from the dimensions that were censored\".format(filtered_pums.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a table, `PUMS_censored`, which has all the records which were censored from our private synopsis.  We can create a differentially private result, treating all of our censored dimensions as a single `other` dimension.  To query these remaining records, we need metadata that describes the new table, `PUMS_censored`.  Since this has the same schema as `PUMS_large`, we can grab the original schema and make a copy for the new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "pc = copy.copy(meta.m_tables['PUMS.PUMS_large'])\n",
    "pc.name = 'PUMS_censored'\n",
    "meta.m_tables['PUMS.PUMS_censored'] = pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|    n|            income|\n",
      "+-----+------------------+\n",
      "|16571|23435.437459062287|\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_single = 'SELECT COUNT(*) AS n, AVG(income) AS income FROM PUMS_censored'\n",
    "missing_dim = private_reader.execute(query_single).persist()\n",
    "missing_dim.createOrReplaceTempView(\"Censored\")\n",
    "missing_dim.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noisy Values for Missing Dimensions\n",
    "\n",
    "Another option is to create a private synopsis for all possible dimension values, where missing values will be set to NULL, which will result in zero counts.  These zero counts will result in zero values.  This approach is not suitable in settings where rare dimensions are private, such as surnames, or when the cross product of all dimensions is very large.  In this case, however, the distinct dimension members are not private, and the cross product is not large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Including empty dimensions, there are 37376 total dimensions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 288:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "alldims = 'SELECT s.*, a.*, e.*, m.*, l.*, b.*, asi.* \\\n",
    "    FROM (SELECT DISTINCT sex FROM PUMS_large) s \\\n",
    "    CROSS JOIN (SELECT DISTINCT age FROM PUMS_large) a \\\n",
    "    CROSS JOIN (SELECT DISTINCT educ FROM PUMS_large) e \\\n",
    "    CROSS JOIN (SELECT DISTINCT married FROM PUMS_large) m \\\n",
    "    CROSS JOIN (SELECT DISTINCT latino FROM PUMS_large) l \\\n",
    "    CROSS JOIN (SELECT DISTINCT black FROM PUMS_large) b \\\n",
    "    CROSS JOIN (SELECT DISTINCT asian FROM PUMS_large) asi'\n",
    "\n",
    "all_dims = reader.execute(alldims)\n",
    "all_dims.persist().createOrReplaceTempView(\"AllDims\")\n",
    "\n",
    "print(\"Including empty dimensions, there are {0} total dimensions\".format(all_dims.count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the empty dimensions increases our total number of dimensions by about 16,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1240489 rows, including empty dimensions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 293:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "joined = 'SELECT p.PersonID, p.state, p.puma, d.sex, d.age, d.educ, d.latino, d.black, d.asian, d.married, p.income \\\n",
    "    FROM AllDims d LEFT OUTER JOIN PUMS_large p ON \\\n",
    "        d.sex = p.sex AND \\\n",
    "        d.age = p.age AND \\\n",
    "        d.educ = p.educ AND \\\n",
    "        d.latino = p.latino AND \\\n",
    "        d.black = p.black AND \\\n",
    "        d.asian = p.asian AND \\\n",
    "        d.married = p.married'\n",
    "\n",
    "joined_pums = reader.execute(joined).persist()\n",
    "joined_pums.createOrReplaceTempView(\"PUMS_joined\")\n",
    "print(\"There are {0} rows, including empty dimensions\".format(joined_pums.count()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = copy.copy(meta.m_tables['PUMS.PUMS_large'])\n",
    "pc.name = 'PUMS_joined'\n",
    "meta.m_tables['PUMS.PUMS_joined'] = pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new private synopsis has 37376 dimensions\n",
      "+-------+------------------+\n",
      "|  count|        avg_income|\n",
      "+-------+------------------+\n",
      "|1240507|30582.638631288974|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 311:>                                                        (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "meta[\"PUMS.PUMS_large\"].censor_dims = False\n",
    "meta[\"PUMS.PUMS_large\"].clamp_counts = False\n",
    "meta[\"PUMS.PUMS_large\"].row_privacy = True\n",
    "\n",
    "\n",
    "q = 'SELECT sex, age, educ, married, latino, black, asian, COUNT(*) AS n, AVG(income) AS income FROM PUMS_joined GROUP BY sex, age, educ, married, latino, black, asian'\n",
    "\n",
    "priv2 = private_reader.execute(q).persist()\n",
    "priv2.createOrReplaceTempView(\"PrivateSynopsis2\")\n",
    "print(\"The new private synopsis has {0} dimensions\".format(priv2.count()))\n",
    "reader.execute(\"SELECT SUM(n) AS count, SUM(income * n) / SUM(n) AS avg_income FROM PrivateSynopsis2\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
